import os
import h5py
import torch
from rdiv import compute_diversity_reward 
from rrep import compute_representativeness_reward
from model import DSN

# Configuration
features_path = "dataset_cpu/features.h5"
log_dir = "outputs/logs"
log_path = os.path.join(log_dir, "training_log.csv")

os.makedirs(log_dir, exist_ok=True)

# Instanciation du model
model = DSN(input_dim=1024, hidden_dim=256)

# Initialisation du log
if not os.path.exists(log_path):
    with open(log_path, 'w') as f:
        f.write("epoch,video_id,reward_div,reward_rep,reward_total\n")

def test_pipeline():
    with h5py.File(features_path, 'r') as hdf:
        video_ids = list(hdf.keys())
        print(f"Vidéos détectées dans le H5 : {len(video_ids)}")
        
        # On teste sur une seule époque pour l'instant
        epoch = 1
        for v_id in video_ids:
            # 1. Chargement
            features = torch.tensor(hdf[v_id][:])
            
            # 2. Simulation de sélection (on prend 15% des images au hasard)
            # comme suggéré dans l'article de Zhou
            n_frames = len(features)
            n_sel = max(2, int(n_frames * 0.15)) 
            indices = torch.randperm(n_frames)[:n_sel]
            selected_features = features[indices]

            # 3. Calculs
            r_div = compute_diversity_reward(selected_features)
            r_rep = compute_representativeness_reward(features, selected_features)
            r_total = (r_div + r_rep) / 2 # Moyenne des deux

            # 4. Affichage et Log
            print(f"Vidéo {v_id} ({n_frames} fr) -> R_total: {r_total:.4f}")
            
            with open(log_path, 'a') as f:
                f.write(f"{epoch},{v_id},{r_div:.4f},{r_rep:.4f},{r_total:.4f}\n")

if __name__ == "__main__":
    test_pipeline()
