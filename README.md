1. ğŸ“¦ PRÃ‰PARATION DE L'ENVIRONNEMENT
2. ğŸ¬ Ã‰TAPE 1 : Organisation des VidÃ©os
3. ğŸ” Ã‰TAPE 2 : Extraction des Features GoogLeNet
4. â¸ï¸  Gestion des Points d'ArrÃªt
5. ğŸ§  Ã‰TAPE 3 : EntraÃ®nement du ModÃ¨le DSN
6. ğŸ“Š Ã‰TAPE 4 : Ã‰valuation et GÃ©nÃ©ration de RÃ©sumÃ©s
7. ğŸ“ Structure des Fichiers
8. ğŸš¨ DÃ©pannage et FAQ

## preparation de l'environnement
```bash
conda activate projet
python scripts/check_environment.py
```
## Structure des dossiers :
- CrÃ©ez la structure de base
video_summarization_project/
â”œâ”€â”€ videos/                          # Vos vidÃ©os originales
â”œâ”€â”€ scripts/                         # Tous les scripts
â”œâ”€â”€ datasets/                        # Datasets gÃ©nÃ©rÃ©s
â”œâ”€â”€ models/                          # ModÃ¨les entraÃ®nÃ©s
â”œâ”€â”€ outputs/                         # RÃ©sumÃ©s gÃ©nÃ©rÃ©s
â””â”€â”€ logs/                            # Logs d'exÃ©cution

# Preparation des videos
** Objectif : PrÃ©parer les videos pour l'extraction **

## PrÃ©paration des videos
Placer les videos dans le dossier videos:
video_summarization_project/videos/
â”œâ”€â”€ votre_video1.mp4
â”œâ”€â”€ votre_video2.avi
â””â”€â”€ ...

## Estimation du temps
``` bash
cd video_summarization_project
python scripts/estimate_time.py --video_folder ./videos --fps 1.0
```
ğŸ¬ 10 vidÃ©os trouvÃ©es
ğŸ“Š Estimation du temps d'extraction:
   DurÃ©e totale vidÃ©o: 85.2 minutes
   Frames Ã  extraire: 5100
   Temps estimÃ©: 3.0 heures


# ETAPE 2 : Extraction des features GooglLeNet
objectif : Extraire les features et les stocker dans HDF5

## Premier lancement
``` bash
cd video_summarization_project
python scripts/extract_features_conda.py \
    --video_folder ./videos \
    --output_dir ./datasets \
    --fps 1.0 \
    --batch_size 8
```

## Suvi de la progression
Pendant l'extraction, suivi de l'extraction
``` bash
cd video_summarization_project
python scripts/extract_features_conda.py \
    --video_folder ./videos \
    --output_dir ./datasets \
    --fps 1.0 \
    --batch_size 8
```
## Suivi de la progression
Pendant l'extraction, suivi de la progression
``` bash
# Dans un autre terminal
tail -f datasets/extraction.log
```

## Structure du HDF5 gÃ©nÃ©rÃ©
datasets/
â”œâ”€â”€ googlenet_features_20240115_143022.h5  # Fichier principal
â”œâ”€â”€ extraction.log                         # Logs dÃ©taillÃ©s
â””â”€â”€ checkpoint.json                       # Ã‰tat d'avancement

** Format HDF5: **
/features/video_0001/features    # (n_frames, 1024)
/features/video_0002/features
...
/metadata/video_ids              # Liste des IDs
/metadata/video_names           # Noms originaux

## VÃ©rification aprÃ¨s extraction
``` bash
python scripts/verify_hdf5.py --hdf5_file ./datasets/googlenet_features_*.h5
```

# Gestion des points d'arrÃªts
## Interruption propre
Appuyez sur Ctrl+C. Le script sauvegarde automatiquement :

    - L'Ã©tat dans checkpoint.json

    - Les features dÃ©jÃ  extraites dans le HDF5

## Reprise aprÃ¨s interruption
``` bash
python scripts/extract_features_conda.py \
    --video_folder ./videos \
    --output_dir ./datasets \
    --fps 1.0 \
    --batch_size 8 \
    --resume
```
Le script :

    Lit checkpoint.json

    Identifie les vidÃ©os dÃ©jÃ  traitÃ©es

    Continue avec les vidÃ©os restantes

4.3 Ã‰tat d'Avancement

Pour voir oÃ¹ vous en Ãªtes :
bash

python scripts/check_progress.py --checkpoint_file ./datasets/checkpoint.json

Sortie :
text

ğŸ“Š Ã‰tat d'avancement :
âœ… TraitÃ©es : 5/10 vidÃ©os
âŒ Ã‰chouÃ©es : 1 vidÃ©o
â³ Restantes : 4 vidÃ©os
ğŸ“… DerniÃ¨re mise Ã  jour : 2024-01-15 14:30:22

5. ğŸ§  Ã‰TAPE 3 : EntraÃ®nement du ModÃ¨le DSN
Objectif : EntraÃ®ner le Deep Summarization Network
5.1 PrÃ©paration des DonnÃ©es d'EntraÃ®nement

Divisez votre dataset :
bash

python scripts/split_dataset.py \
    --hdf5_file ./datasets/googlenet_features_*.h5 \
    --train_ratio 0.7 \
    --val_ratio 0.15 \
    --test_ratio 0.15

RÃ©sultat :
text

datasets/
â”œâ”€â”€ splits.json                    # RÃ©partition train/val/test
â””â”€â”€ googlenet_features_*.h5       # MÃªmes features, split dans mÃ©tadonnÃ©es

5.2 Configuration d'EntraÃ®nement

CrÃ©ez un fichier de configuration :
yaml

# configs/training_config.yaml
model:
  feature_dim: 1024
  hidden_dim: 256
  lambda_temporal: 20

training:
  batch_size: 4
  learning_rate: 0.0001
  num_epochs: 60
  n_episodes: 5
  
regularization:
  beta1: 0.01      # Poids rÃ©gularisation pourcentage
  beta2: 0.0001    # Poids rÃ©gularisation L2
  epsilon: 0.15    # Pourcentage cible de sÃ©lection

5.3 Lancement de l'EntraÃ®nement
bash

python scripts/train_dsn.py \
    --config configs/training_config.yaml \
    --hdf5_file ./datasets/googlenet_features_*.h5 \
    --output_dir ./models \
    --experiment_name first_training

5.4 Suivi de l'EntraÃ®nement

Pendant l'entraÃ®nement :
bash

# Suivre les logs
tail -f models/first_training/training.log

# Visualiser les mÃ©triques
tensorboard --logdir models/first_training/tensorboard

Fichiers gÃ©nÃ©rÃ©s :
text

models/first_training/
â”œâ”€â”€ checkpoint_epoch_10.pth       # Checkpoint toutes les 10 Ã©poques
â”œâ”€â”€ best_model.pth                # Meilleur modÃ¨le
â”œâ”€â”€ training_history.json         # Historique des mÃ©triques
â”œâ”€â”€ config.yaml                   # Configuration sauvegardÃ©e
â””â”€â”€ tensorboard/                  # Logs TensorBoard

5.5 Reprise de l'EntraÃ®nement

Pour reprendre un entraÃ®nement interrompu :
bash

python scripts/train_dsn.py \
    --config configs/training_config.yaml \
    --hdf5_file ./datasets/googlenet_features_*.h5 \
    --output_dir ./models \
    --experiment_name first_training \
    --resume_from_checkpoint models/first_training/checkpoint_epoch_20.pth

5.6 Early Stopping

L'entraÃ®nement s'arrÃªte automatiquement si :

    Pas d'amÃ©lioration depuis 10 Ã©poques

    Atteint le nombre maximum d'Ã©poques (60)

    Vous appuyez sur Ctrl+C

6. ğŸ“Š Ã‰TAPE 4 : Ã‰valuation et GÃ©nÃ©ration de RÃ©sumÃ©s
6.1 Ã‰valuation sur le Test Set
bash

python scripts/evaluate_model.py \
    --model_path ./models/first_training/best_model.pth \
    --hdf5_file ./datasets/googlenet_features_*.h5 \
    --split test \
    --output_dir ./outputs/evaluation

MÃ©triques calculÃ©es :

    F-score (si annotations disponibles)

    R_div (diversitÃ©)

    R_rep (reprÃ©sentativitÃ©)

6.2 GÃ©nÃ©ration de RÃ©sumÃ©s

Pour une vidÃ©o spÃ©cifique :
bash

python scripts/generate_summary.py \
    --model_path ./models/first_training/best_model.pth \
    --video_path ./videos/votre_video.mp4 \
    --output_dir ./outputs/summaries \
    --summary_percentage 0.15

6.3 Visualisation des RÃ©sultats
bash

python scripts/visualize_summary.py \
    --summary_file ./outputs/summaries/votre_video_summary.h5 \
    --video_path ./videos/votre_video.mp4 \
    --output_image ./outputs/visualizations/summary_visualization.png

Fichiers gÃ©nÃ©rÃ©s :
text

outputs/summaries/
â”œâ”€â”€ votre_video_summary.h5          # RÃ©sumÃ© structurÃ©
â”œâ”€â”€ votre_video_scores.npy          # Scores d'importance
â””â”€â”€ votre_video_selected_frames.txt # Indices des frames sÃ©lectionnÃ©es

outputs/visualizations/
â””â”€â”€ summary_visualization.png       # Graphique visuel

7. ğŸ“ Structure ComplÃ¨te des Fichiers
text

video_summarization_project/
â”‚
â”œâ”€â”€ videos/                          # VIDÃ‰OS SOURCES
â”‚   â”œâ”€â”€ raw/                        # VidÃ©os originales
â”‚   â””â”€â”€ processed/                  # VidÃ©os prÃ©traitÃ©es (optionnel)
â”‚
â”œâ”€â”€ scripts/                         # TOUS LES SCRIPTS
â”‚   â”œâ”€â”€ 01_environment_check.py
â”‚   â”œâ”€â”€ 02_extract_features.py
â”‚   â”œâ”€â”€ 03_train_model.py
â”‚   â”œâ”€â”€ 04_evaluate.py
â”‚   â”œâ”€â”€ 05_generate_summary.py
â”‚   â”œâ”€â”€ 06_visualize.py
â”‚   â”œâ”€â”€ utils/                      # Fonctions utilitaires
â”‚   â””â”€â”€ configs/                    # Fichiers de configuration
â”‚
â”œâ”€â”€ datasets/                       # DONNÃ‰ES GÃ‰NÃ‰RÃ‰ES
â”‚   â”œâ”€â”€ raw/                        # Features brutes
â”‚   â”œâ”€â”€ processed/                  # DonnÃ©es prÃ©parÃ©es
â”‚   â”œâ”€â”€ splits.json                 # Division train/val/test
â”‚   â””â”€â”€ checkpoints/                # Points de reprise extraction
â”‚
â”œâ”€â”€ models/                         # MODÃˆLES ENTRÃ‚INÃ‰S
â”‚   â”œâ”€â”€ experiment_1/
â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â”œâ”€â”€ training_history.json
â”‚   â”‚   â””â”€â”€ checkpoints/
â”‚   â””â”€â”€ experiment_2/
â”‚
â”œâ”€â”€ outputs/                        # RÃ‰SULTATS
â”‚   â”œâ”€â”€ evaluations/                # MÃ©triques d'Ã©valuation
â”‚   â”œâ”€â”€ summaries/                  # RÃ©sumÃ©s gÃ©nÃ©rÃ©s
â”‚   â””â”€â”€ visualizations/             # Graphiques et visualisations
â”‚
â”œâ”€â”€ logs/                           # LOGS D'EXÃ‰CUTION
â”‚   â”œâ”€â”€ extraction_20240115.log
â”‚   â”œâ”€â”€ training_20240116.log
â”‚   â””â”€â”€ evaluation_20240117.log
â”‚
â””â”€â”€ README.md                       # Cette documentation

